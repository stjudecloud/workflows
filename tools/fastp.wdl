version 1.1

task fastp {
    meta {
        description: "Runs the `fastp` tool for FASTQ quality control and trimming"
        outputs: {
            read_one_fastq_gz: "The gzipped trimmed read one FASTQ file. Only generated if `read_two_fastq` is supplied and `output_fastq` is `true`. Has the name `~{prefix}.R1.fastq.gz`.",
            read_two_fastq_gz: "The gzipped trimmed read two FASTQ file. Only generated if `read_two_fastq` is supplied and `output_fastq` is `true`. Has the name `~{prefifx}.R2.fastq.gz.",
            single_end_reads_fastq_gz: "The trimmed Single-End FASTQ file. Only generated if `read_two_fastq` is not supplied and `output_fastq` is `true`. Has the name `~{prefix}.fastq.gz`.",
            report: "The HTML report generated by `fastp`",
            report_json: "The JSON report generated by `fastp`",
        }
    }

    parameter_meta {
        read_one_fastq: "Input FASTQ with read one. Can be gzipped or uncompressed."
        read_two_fastq: "Optional input FASTQ with read two. Can be gzipped or uncompressed."
        prefix: "Prefix for the output files. The extensions `.fastp.html`, `.fastp.json`, `.R1.fastq.gz`, `.R2.fastq.gz`, and/or `.fastq.gz` will be added."
        output_fastq: "Output FASTQ files (true) or only generate a `fastp` QC report (false)?"
        deduplicate: "Remove detected duplicate reads/pairs?"
        disable_duplicate_eval: "Don't evaluate duplication rate? Decreases runtime."
        disable_quality_filter: "Disable quality score filtering?"
        disable_length_filter: "Disable read length filtering?"
        enable_complexity_filter: "Enable low complexity filter?"
        enable_overrepresentation_eval: {
            description: "Enable overrepresented sequence analysis?",
            tool_default: false,
        }
        disable_adapter_trimming: "Disable adapter trimming?"
        enable_pe_adapter_trimming: {
            description: "Enable adapter detection for Paired-End data to get ultra-clean data? It takes more time to find just a little bit more adapters.",
            tool_default: false,
        }
        allow_gap_overlap_trimming: "Allow up to one gap when trimming adapters by overlap analysis for Paired-End data?"
        enable_base_correction: "Enable base correction in overlapped regions? Only for Paired-End data."
        phred64: "Input uses phred64 encoding. It will be converted to phred33 encoding in the output files."
        use_all_cores: "Use all cores? Recommended for cloud environments."
        first_n_reads: "Only process the first `n` reads. `first_n_reads = 0` for processing entire input."
        duplicate_accuracy: "Accuracy level to calculate duplication. Value must be between 1 and 6 inclusive. Higher levels use more memory (by default: 2 GB, 4 GB, 6 GB, 12 GB, 20 GB, 32 GB)."
        n_base_limit: "If one read's number of N base is `>n_base_limit`, then this read/pair is discarded."
        qualified_quality: "The PHRED quality score value that determines whether a base is qualified."
        unqualified_percent: "What percentage of bases is allowed to be unqualified (0-100)."
        average_quality: "If one read's average quality score `< average_quality`, then this read/pair is discarded. `0` means no requirement."
        length_required: "Reads shorter than `length_required` will be discarded."
        length_limit: "Reads longer than `length_limit` will be discarded. `0` means no limitation."
        complexity_threshold: "The threshold for the low complexity filter (0-100). A value of 30 would mean 30% complexity is required."
        overlap_len_require: "The minimum length to detect overlapped region of Paired-End reads. This will affect overlap analysis based Paired-End adapter trimming and correction."
        overlap_diff_limit: "The maximum number of mismatched bases to detect overlapped region of Paired-End reads. This will affect overlap analysis based Paired-End adapter trimming and correction."
        overlap_diff_percent_limit: "The maximum percentage of mismatched bases to detect overlapped region of Paired-End reads. This will affect overlap analysis based Paired-End adapter trimming and correction."
        overrepresentation_sampling: "One in `overrepresentation_sampling` reads will be computed for overrepresentation analysis. Value should be between 1 and 10000 inclusive. Smaller values will run slower."
        trim_front_r1: "Number of bases to trim from the front of read one"
        trim_tail_r1: "Number of bases to trim from the tail of read one"
        trim_front_r2: "Number of bases to trim from the front of read two"
        trim_tail_r2: "Number of bases to trim from the tail of read two"
        max_length_r1: "Maximum length of read one. Reads longer than this will be trimmed from the tail."
        max_length_r2: "Maximum length of read two. Reads longer than this will be trimmed from the tail."
        modify_disk_size_gb: "Add to or subtract from dynamic disk space allocation. Default disk size is determined by the size of the inputs. Specified in GB."
        ncpu: "Number of cores to allocate for task"
    }

    input {
        File read_one_fastq
        File? read_two_fastq
        String prefix = sub(
            basename(read_one_fastq),
            "(([_.][rR](?:ead)?[12])((?:[_.-][^_.-]*?)*?))?\\.(fastq|fq)(\\.gz)?$",
            ""  # Once replacing with capturing groups is supported, replace with group 3
        ) + ".trimmed"
        Boolean output_fastq = true
        Boolean deduplicate = false
        Boolean disable_duplicate_eval = false
        Boolean disable_quality_filter = false
        Boolean disable_length_filter = false
        Boolean enable_complexity_filter = false
        Boolean enable_overrepresentation_eval = true
        Boolean disable_adapter_trimming = false
        Boolean enable_pe_adapter_trimming = true
        Boolean allow_gap_overlap_trimming = false
        Boolean enable_base_correction = false
        Boolean phred64 = false
        Boolean use_all_cores = false
        Int first_n_reads = 0
        Int duplicate_accuracy = if deduplicate then 3 else 1
        Int n_base_limit = 5
        Int qualified_quality = 15
        Int unqualified_percent = 40
        Int average_quality = 0
        Int length_required = 15
        Int length_limit = 0
        Int complexity_threshold = 30
        Int overlap_len_require = 30
        Int overlap_diff_limit = 5
        Int overlap_diff_percent_limit = 20
        Int overrepresentation_sampling = 20
        Int trim_front_r1 = 0
        Int trim_tail_r1 = 0
        Int trim_front_r2 = 0
        Int trim_tail_r2 = 0
        Int max_length_r1 = 0
        Int max_length_r2 = 0
        Int modify_disk_size_gb = 0
        Int ncpu = 3
    }

    Map[Int, String] dup_acc_to_mem = {
        1: "2 GB",
        2: "4 GB",
        3: "6 GB",
        4: "12 GB",
        5: "20 GB",
        6: "32 GB",
    }

    Float input_size = size(read_one_fastq, "GB") + size(read_two_fastq, "GB")
    Int disk_size_gb = ceil(input_size) * 2 + 10 + modify_disk_size_gb

    command <<< 
        set -euo pipefail

        n_cores=~{ncpu}
        if ~{use_all_cores}; then
            n_cores=$(nproc)
        fi

        # set ENV variables for `fastp`
        export LC_ALL=C.UTF-8
        export LANG=C.UTF-8

        fastp \
            -i "~{read_one_fastq}" \
            ~{"-I '" + read_two_fastq + "'"} \
            ~{(
                if output_fastq
                then "-o '" + (
                    if defined(read_two_fastq)
                    then "~{prefix}.R1.fastq.gz"
                    else "~{prefix}.fastq.gz"
                ) + "'"
                else ""
            )} \
            ~{(
                if (defined(read_two_fastq) && output_fastq)
                then "-O '" + prefix + ".R2.fastq.gz'"
                else ""
            )} \
            --reads_to_process ~{first_n_reads} \
            ~{if deduplicate then "--dedup" else ""} \
            --dup_calc_accuracy ~{duplicate_accuracy} \
            ~{if disable_duplicate_eval then "--dont_eval_duplication" else ""} \
            ~{if phred64 then "--phred64" else ""} \
            ~{if disable_quality_filter then "--disable_quality_filtering" else ""} \
            -n ~{n_base_limit} \
            -q ~{qualified_quality} \
            -u ~{unqualified_percent} \
            -e ~{average_quality} \
            ~{if disable_length_filter then "--disable_length_filtering" else ""} \
            -l ~{length_required} \
            --length_limit ~{length_limit} \
            ~{if enable_complexity_filter then "-y" else ""} \
            -Y ~{complexity_threshold} \
            ~{if enable_overrepresentation_eval then "-p" else ""} \
            -P ~{overrepresentation_sampling} \
            ~{if disable_adapter_trimming then "--disable_adapter_trimming" else ""} \
            ~{if enable_pe_adapter_trimming then "-2" else ""} \
            ~{if allow_gap_overlap_trimming then "--allow_gap_overlap_trimming" else ""} \
            ~{if enable_base_correction then "-c" else ""} \
            --overlap_len_require ~{overlap_len_require} \
            --overlap_diff_limit ~{overlap_diff_limit} \
            --overlap_diff_percent_limit ~{overlap_diff_percent_limit} \
            --trim_front1 ~{trim_front_r1} \
            --trim_tail1 ~{trim_tail_r1} \
            --trim_front2 ~{trim_front_r2} \
            --trim_tail2 ~{trim_tail_r2} \
            --max_len1 ~{max_length_r1} \
            --max_len2 ~{max_length_r2} \
            -R "~{prefix} report" \
            --thread "$n_cores" \
            -h "~{prefix}.fastp.html" \
            -j "~{prefix}.fastp.json"
    >>>

    output {
        File? read_one_fastq_gz = prefix + ".R1.fastq.gz"
        File? read_two_fastq_gz = prefix + ".R2.fastq.gz"
        File? single_end_reads_fastq_gz = prefix + ".fastq.gz"
        File report = prefix + ".fastp.html"
        File report_json = prefix + ".fastp.json"
    }

    runtime {
        cpu: ncpu
        memory: (
            if disable_duplicate_eval
            then "2 GB"
            else dup_acc_to_mem[duplicate_accuracy]
        )
        disks: "~{disk_size_gb} GB"
        container: "quay.io/biocontainers/fastp:1.0.1--heae3180_0"
        maxRetries: 1
    }
}
