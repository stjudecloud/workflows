version 1.0

import "../../tools/star.wdl"
import "../general/alignment-post.wdl" as align_post
import "../../tools/htseq.wdl"
import "../../tools/ngsderive.wdl"

workflow rnaseq_core {
    input {
        Array[File] read_one_fastqs
        Array[File] read_two_fastqs
        String read_groups
        String output_prefix
        File gtf
        File stardb
        Boolean mark_duplicates = false
        File? contaminant_db
        Boolean cleanse_xenograft = false
        String xenocp_aligner = "star"
        String strandedness = ""
        Boolean detect_nproc = false
        Int? max_retries
    }
    
    parameter_meta {
        read_one_fastqs: "Input Fastq format file(s) with 1st read in pair to align"
        read_two_fastqs: "Input Fastq format file(s) with 2nd read in pair to align"
        read_groups: "A space-delimited read group record for each read group. Exactly one fastq filename must match each read group ID from `read_one_fastqs` and `read_two_fastqs`. Read group fields (Required fields: ID, LB, PL, PU, & SM.) should be space delimited. Read groups should be comma separated, with a space on each side (e.g. ' , '). The ID field must come first for each read group and must match the basename of a fastq file (up to the first period). Expected form: `ID:rg1 PU:flowcell1.lane1 SM:sample1 PL:illumina LB:sample1_lib1 , ID:rg2 PU:flowcell1.lane2 SM:sample1 PL:illumina LB:sample1_lib1`"
        output_prefix: "Prefix for output files"
        gtf: "GTF feature file"
        stardb: "Database of reference files for the STAR aligner. Can be generated by `star-db-build.wdl`"
        mark_duplicates: "Add SAM flag to computationally determined duplicate reads?"
        contaminant_db: "A compressed reference database corresponding to the aligner chosen with `xenocp_aligner` for the contaminant genome"
        cleanse_xenograft: "If true, use XenoCP to unmap reads from contaminant genome"
        xenocp_aligner: "Aligner to use to map reads to the host genome to detect contamination: [bwa aln, bwa mem, star]"
        strandedness: "empty, 'Stranded-Reverse', 'Stranded-Forward', or 'Unstranded'. If missing, will be inferred"
        detect_nproc: "Use all available cores for multi-core steps?"
        max_retries: "Number of times to retry failed steps. Overrides task level defaults."
    }

    call star.alignment { input:
        read_one_fastqs=read_one_fastqs,
        read_two_fastqs=read_two_fastqs,
        stardb_tar_gz=stardb,
        output_prefix=output_prefix,
        read_groups=read_groups,
        detect_nproc=detect_nproc,
        max_retries=max_retries
    }

    call align_post.alignment_post { input:
        bam=alignment.star_bam,
        mark_duplicates=mark_duplicates,
        contaminant_db=contaminant_db,
        xenocp_aligner=xenocp_aligner,
        cleanse_xenograft=cleanse_xenograft,
        detect_nproc=detect_nproc,
        max_retries=max_retries
    }

    call ngsderive.infer_strandedness as ngsderive_strandedness { input:
        bam=alignment_post.out_bam,
        bam_index=alignment_post.bam_index,
        gtf=gtf,
        max_retries=max_retries
    }

    call htseq.count as htseq_count { input:
        bam=alignment_post.out_bam,
        gtf=gtf,
        provided_strandedness=strandedness,
        inferred_strandedness=ngsderive_strandedness.strandedness,
        max_retries=max_retries
    }

    output {
        File bam = alignment_post.out_bam
        File bam_index = alignment_post.bam_index
        File bam_checksum = alignment_post.bam_checksum
        File star_log = alignment.star_log
        File gene_counts = htseq_count.gene_counts
        File inferred_strandedness = ngsderive_strandedness.strandedness_file
        File bigwig = alignment_post.bigwig
    }
}