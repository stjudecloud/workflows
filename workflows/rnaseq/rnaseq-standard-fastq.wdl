## # RNA-Seq Standard from FastQ
##
## This WDL workflow runs the STAR RNA-Seq alignment workflow for St. Jude Cloud from FastQ input.
## The workflow takes paired input FastQ files. 
## The read pairs are then passed through STAR alignment to generate a BAM file. The BAM is run
## through several QC steps. Quantification is done using htseq-count. 
##
## ## LICENSING
##
## #### MIT License
##
## Copyright 2020-Present St. Jude Children's Research Hospital
##
## Permission is hereby granted, free of charge, to any person obtaining a copy of this
## software and associated documentation files (the "Software"), to deal in the Software
## without restriction, including without limitation the rights to use, copy, modify, merge,
## publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons
## to whom the Software is furnished to do so, subject to the following conditions:
##
## The above copyright notice and this permission notice shall be included in all copies or
## substantial portions of the Software.
##
## THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
## BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
## NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
## DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
## OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

version 1.0

import "../../tools/fq.wdl"
import "./rnaseq-core.wdl" as rna_core

workflow rnaseq_standard_fastq {
    parameter_meta {
        gtf: "Gzipped GTF feature file"
        stardb: "Database of reference files for the STAR aligner. The name of the root directory which was archived must match the archive's filename without the `.tar.gz` extension. Can be generated by `star-db-build.wdl`"
        read_one_fastqs: "Input Fastq format file(s) with 1st read in pair to align"
        read_two_fastqs: "Input Fastq format file(s) with 2nd read in pair to align"
        read_groups: "A space-delimited read group record for each read group. Exactly one FastQ filename must match each read group ID from `read_one_fastqs` and `read_two_fastqs`. Read group fields (Required fields: ID, LB, PL, PU, & SM.) should be space delimited. Read groups should be comma separated, with a space on each side (e.g. ' , '). The ID field must come first for each read group and must match the basename of a FastQ file (up to the first period). Expected form: `ID:rg1 PU:flowcell1.lane1 SM:sample1 PL:illumina LB:sample1_lib1 , ID:rg2 PU:flowcell1.lane2 SM:sample1 PL:illumina LB:sample1_lib1`"
        output_prefix: "Prefix for output files"
        contaminant_db: "A compressed reference database corresponding to the aligner chosen with `xenocp_aligner` for the contaminant genome"
        max_retries: "Number of times to retry failed steps. Overrides task level defaults."
        xenocp_aligner: {
            description: "Aligner to use to map reads to the host genome for detecting contamination"
            choices: [
                'bwa aln',
                'bwa mem',
                'star'
            ]
        },
        strandedness: {
            description: "Strandedness protocol of the RNA-Seq experiment. If unspecified, strandedness will be inferred by `ngsderive`."
            choices: [
                '',
                'Stranded-Reverse',
                'Stranded-Forward',
                'Unstranded'
            ]
        },
        mark_duplicates: "Add SAM flag to computationally determined duplicate reads?"
        cleanse_xenograft: "Use XenoCP to unmap reads from contaminant genome?"
        validate_input: "TODO write this"
        use_all_cores: "Use all cores for multi-core steps?"
        subsample_n_reads: "Only process a random sampling of `n` reads. Any `n`<=`0` for processing entire input."
    }

    input {
        File gtf
        File stardb
        Array[File] read_one_fastqs
        Array[File] read_two_fastqs
        String read_groups
        String output_prefix
        File? contaminant_db
        Int? max_retries
        String xenocp_aligner = "star"
        String strandedness = ""
        Boolean mark_duplicates = false
        Boolean cleanse_xenograft = false
        Boolean validate_input = true
        Boolean use_all_cores = false
        Int subsample_n_reads = -1
    }

    call parse_input { input:
        input_strand=strandedness,
        cleanse_xenograft=cleanse_xenograft,
        contaminant_db=defined(contaminant_db)
    }

    if (validate_input){
        scatter (reads in zip(read_one_fastqs, read_two_fastqs)) {
            call fq.fqlint { input:
                read_one_fastq_gz=reads.left,
                read_two_fastq_gz=reads.right,
                max_retries=max_retries
            }
        }
    }

    if (subsample_n_reads > 0) {
        Int reads_per_pair = ceil(subsample_n_reads / length(read_one_fastqs))
        scatter (reads in zip(read_one_fastqs, read_two_fastqs)) {
            call fq.subsample { input:
                read_one_fastq_gz=reads.left,
                read_two_fastq_gz=reads.right,
                record_count=reads_per_pair,
                max_retries=max_retries
            }
        }
    }
    Array[File] selected_read_one_fastqs = select_first([
        subsample.subsampled_read1,
        read_one_fastqs
    ])
    Array[File] selected_read_two_fastqs = select_all(
        select_first([
            subsample.subsampled_read2,
            read_two_fastqs
        ])
    )

    call rna_core.rnaseq_core { input:
        read_one_fastqs=selected_read_one_fastqs,
        read_two_fastqs=selected_read_two_fastqs,
        read_groups=read_groups,
        output_prefix=output_prefix,
        gtf=gtf,
        stardb=stardb,
        mark_duplicates=mark_duplicates,
        contaminant_db=contaminant_db,
        cleanse_xenograft=cleanse_xenograft,
        xenocp_aligner=xenocp_aligner,
        strandedness=strandedness,
        use_all_cores=use_all_cores,
        max_retries=max_retries
    }

    output {
        File bam = rnaseq_core.bam
        File bam_index = rnaseq_core.bam_index
        File bam_checksum = rnaseq_core.bam_checksum
        File star_log = rnaseq_core.star_log
        File feature_counts = rnaseq_core.feature_counts
        File inferred_strandedness = rnaseq_core.inferred_strandedness
        String inferred_strandedness_string = rnaseq_core.inferred_strandedness_string
        File bigwig = rnaseq_core.bigwig
    }
}

task parse_input {
    # TODO this is the exact same code as parse_input in the BAM entrypoint
    input {
        String input_strand
        Boolean cleanse_xenograft
        Boolean contaminant_db
        Int memory_gb = 4
        Int disk_size_gb = 1
        Int max_retries = 1
    }

    command <<<
        if [ -n "~{input_strand}" ] \
            && [ "~{input_strand}" != "Stranded-Reverse" ] \
            && [ "~{input_strand}" != "Stranded-Forward" ] \
            && [ "~{input_strand}" != "Unstranded" ]
        then
            >&2 echo "strandedness must be:"
            >&2 echo "'', 'Stranded-Reverse', 'Stranded-Forward', or 'Unstranded'"
            exit 1
        fi

        if ~{cleanse_xenograft} && [ ! ~{contaminant_db} ]; then
            >&2 echo "'contaminant_db' must be supplied if 'cleanse_xenograft' is 'true'"
            exit 1
        fi
    >>>

    output {
        String input_check = "passed"
    }

    runtime {
        memory: memory_gb + " GB"
        disk: disk_size_gb + " GB"
        docker: 'ghcr.io/stjudecloud/util:1.2.0'
        maxRetries: max_retries
    }
}
