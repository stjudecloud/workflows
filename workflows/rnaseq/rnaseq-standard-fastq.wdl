## # RNA-Seq Standard from FastQ
##
## This WDL workflow runs the STAR RNA-seq alignment workflow for St. Jude Cloud from fastq input.
## The workflow takes paired input fastq files. 
## The read pairs are then passed through STAR alignment to generate a BAM file. The BAM is run
## through several QC steps. Quantification is done using htseq-count. 
##
## ## LICENSING
##
## #### MIT License
##
## Copyright 2019 St. Jude Children's Research Hospital
##
## Permission is hereby granted, free of charge, to any person obtaining a copy of this
## software and associated documentation files (the "Software"), to deal in the Software
## without restriction, including without limitation the rights to use, copy, modify, merge,
## publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons
## to whom the Software is furnished to do so, subject to the following conditions:
##
## The above copyright notice and this permission notice shall be included in all copies or
## substantial portions of the Software.
##
## THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
## BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
## NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
## DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
## OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

version 1.0

import "https://raw.githubusercontent.com/stjudecloud/workflows/master/tools/fq.wdl"
import "https://raw.githubusercontent.com/stjudecloud/workflows/master/tools/star.wdl"
import "https://raw.githubusercontent.com/stjudecloud/workflows/master/tools/picard.wdl"
import "https://raw.githubusercontent.com/stjudecloud/workflows/master/tools/ngsderive.wdl"
import "https://raw.githubusercontent.com/stjudecloud/workflows/master/tools/htseq.wdl"
import "https://raw.githubusercontent.com/stjudecloud/workflows/master/tools/samtools.wdl"
import "https://raw.githubusercontent.com/stjudecloud/workflows/master/tools/util.wdl"
import "https://raw.githubusercontent.com/stjudecloud/workflows/master/tools/deeptools.wdl"

workflow rnaseq_standard_fastq {
    input {
        File gencode_gtf
        Array[File] read_one_fastqs
        Array[File] read_two_fastqs
        File stardb_tar_gz
        String strandedness = ""
        String output_prefix
        String read_groups
        Int max_retries = 1
        Boolean detect_nproc = false
        Boolean validate_input = true
    }

    parameter_meta {
        gencode_gtf: "GTF file provided by Gencode"
        read_one_fastqs: "Input Fastq format file(s) with 1st read in pair to align"
        read_two_fastqs: "Input Fastq format file(s) with 2nd read in pair to align"
        stardb_tar_gz: "Database of reference files for the STAR aligner. Can be generated by `rnaseq-star-db-build.wdl`"
        strandedness: "empty, 'Stranded-Reverse', 'Stranded-Forward', or 'Unstranded'. If missing, will be inferred"
        output_prefix: "Prefix for output files"
        read_groups: "A space-delimited read group record for each read group. Exactly one fastq filename must match each read group ID from `read_one_fastqs` and `read_two_fastqs`. Expected form: `ID:rg1 PU:flowcell1.lane1 SM:sample1 PL:illumina LB:sample1_lib1 , ID:rg2 PU:flowcell1.lane2 SM:sample1 PL:illumina LB:sample1_lib1`"
        max_retries: "Number of times to retry failed steps"
        detect_nproc: "Use all available cores for multi-core steps"
    }

    String provided_strandedness = strandedness

    call parse_input { input: input_strand=provided_strandedness }
    if (validate_input){
        scatter (reads in zip(read_one_fastqs, read_two_fastqs)) {
            call fq.fqlint { input: read1=reads.left, read2=reads.right, max_retries=max_retries }
        }
    }

    call star.alignment {
        input:
            read_one_fastqs=read_one_fastqs,
            read_two_fastqs=read_two_fastqs,
            stardb_tar_gz=stardb_tar_gz,
            output_prefix=output_prefix,
            read_groups=read_groups,
            max_retries=max_retries,
            detect_nproc=detect_nproc
    }
    call picard.sort as picard_sort { input: bam=alignment.star_bam, max_retries=max_retries }
    call samtools.index as samtools_index { input: bam=picard_sort.sorted_bam, max_retries=max_retries, detect_nproc=detect_nproc }
    call picard.validate_bam { input: bam=picard_sort.sorted_bam, max_retries=max_retries }
    call ngsderive.infer_strandedness as ngsderive_strandedness { input: bam=picard_sort.sorted_bam, bai=samtools_index.bai, gtf=gencode_gtf, max_retries=max_retries }
    call htseq.count as htseq_count { input: bam=picard_sort.sorted_bam, gtf=gencode_gtf, provided_strandedness=provided_strandedness, inferred_strandedness=ngsderive_strandedness.strandedness, max_retries=max_retries }
    call deeptools.bamCoverage as deeptools_bamCoverage { input: bam=picard_sort.sorted_bam, bai=samtools_index.bai, max_retries=max_retries }

    output {
        File bam = picard_sort.sorted_bam
        File bam_index = samtools_index.bai
        File star_log = alignment.star_log
        File gene_counts = htseq_count.out
        File inferred_strandedness = ngsderive_strandedness.strandedness_file
        File bigwig = deeptools_bamCoverage.bigwig
    }
}

task parse_input {
    input {
        String input_strand
    }

    command {
        if [ -n "~{input_strand}" ] && [ "~{input_strand}" != "Stranded-Reverse" ] && [ "~{input_strand}" != "Stranded-Forward" ] && [ "~{input_strand}" != "Unstranded" ]; then
            >&2 echo "strandedness must be empty, 'Stranded-Reverse', 'Stranded-Forward', or 'Unstranded'"
            exit 1
        fi
    }

    runtime {
        disk: "1 GB"
        docker: 'stjudecloud/util:1.0.0'
    }

    output {
        String input_check = "passed"
    }
}
