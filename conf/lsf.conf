include required(classpath("application"))

call-caching {
  enabled = false
}

database {
  profile = "slick.jdbc.HsqldbProfile$"
  db {
    driver = "org.hsqldb.jdbcDriver"
    url = """
    jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;
    shutdown=false;
    hsqldb.default_table_type=cached;hsqldb.tx=mvcc;
    hsqldb.result_max_memory_rows=10000;
    hsqldb.large_data=true;
    hsqldb.applog=1;
    hsqldb.lob_compressed=true;
    hsqldb.script_format=3
    hsqldb.lock_file=false
    """
    connectionTimeout = 120000
    numThreads = 1
   }
}

backend {
  default = LSF
  providers {
    LSF {
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
      config {
        filesystems {
          local {
            localization: ["hard-link", "soft-link", "cached-copy", "copy"]
          }
        }

        runtime-attributes = """
        Int cpu = 1
        Int hosts = 1
        Int? memory_mb = 4096
        String lsf_queue = "compbio"
        String? lsf_job_group
        String? docker
        """

        submit = """
          bsub \
            -q ${lsf_queue} \
            -n ${cpu} \
            ${"-g " + lsf_job_group} \
            -R "rusage[mem=${round(round(memory_mb)/cpu)}] span[hosts=${hosts}]" \
            -J ${job_name} \
            -cwd ${cwd} \
            -o ${cwd}/execution/stdout.lsf \
            -e ${cwd}/execution/stderr.lsf \
            /usr/bin/env bash ${script}
        """

        submit-docker = """
          # Make sure the SINGULARITY_CACHEDIR variable is set. If not use a default
          # based on the users home.
          if [ -z $SINGULARITY_CACHEDIR ];
              then CACHE_DIR=$HOME/.singularity/cache
              else CACHE_DIR=$SINGULARITY_CACHEDIR
          fi
          # Make sure cache dir exists so lock file can be created by flock
          mkdir -p $CACHE_DIR
          LOCK_FILE=$CACHE_DIR/singularity_pull_flock
          # Create an exclusive filelock with flock.
          # This avoids cache corruption if multiple workers attempt to
          # access the cache simultaneously.
          # From: https://cromwell.readthedocs.io/en/stable/tutorials/Containers/#job-schedulers
          flock --exclusive --timeout 900 $LOCK_FILE \
          singularity exec --containall docker://${docker} \
          echo "Singularity pulled ${docker} successfully"

          bsub \
            -q ${lsf_queue} \
            -n ${cpu} \
            ${"-g " + lsf_job_group} \
            -R "rusage[mem=${round(round(memory_mb)/cpu)}] span[hosts=${hosts}]" \
            -J ${job_name} \
            -cwd ${cwd} \
            -o ${cwd}/execution/stdout.lsf \
            -e ${cwd}/execution/stderr.lsf \
            "singularity exec --containall --workdir /scratch_local --bind ${cwd}:${docker_cwd} docker://${docker} ${job_shell} ${docker_script}"
        """


        kill = "bkill ${job_id}"
	# check-job-alive must be present in $PATH for Cromwell to properly check job status
        check-alive = "check-job-alive ${job_id}"

        job-id-regex = "Job <(\\d+)>.*"

        exit-code-timeout-seconds = 120
      }
    }
  }
}
